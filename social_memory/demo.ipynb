{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" elasticsearch:8.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造social跟knowledge数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# 连接到Elasticsearch\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# 创建social memory索引\n",
    "def create_social_memory_index(index_name):\n",
    "    settings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"text\"},\n",
    "                \"other-names\": {\"type\": \"text\"},\n",
    "                \"description\": {\"type\": \"text\"},\n",
    "                \"impression\": {\"type\": \"text\"},\n",
    "                \"relationship\": {\"type\": \"text\"},\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body=settings)\n",
    "\n",
    "# 创建knowledge memory索引\n",
    "def create_knowledge_memory_index(index_name):\n",
    "    settings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"text\"},\n",
    "                \"description\": {\"type\": \"text\"},\n",
    "                \"learning_context\": {\"type\": \"text\"},\n",
    "                \"knowledge_content\": {\"type\": \"text\"},\n",
    "                \"outcome\": {\"type\": \"text\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body=settings)\n",
    "\n",
    "# 创建interaction memory索引\n",
    "def create_interaction_memory_index(index_name):\n",
    "    settings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"name\": {\"type\": \"text\"},\n",
    "                \"event_id\": {\"type\": \"text\"},\n",
    "                \"description\": {\"type\": \"text\"},\n",
    "                \"impression\": {\"type\": \"text\"},\n",
    "                \"interaction\": {\"type\": \"text\"},\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body=settings)\n",
    "\n",
    "# 搜索memory，支持多个字段\n",
    "def search_existing_memory(index_name, query, fields, min_score=1.0, size=1):\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": fields,\n",
    "                \"fuzziness\": \"AUTO\"  # 自动模糊匹配\n",
    "            }\n",
    "        },\n",
    "        \"min_score\": min_score,  # 仅返回 _score 大于等于 min_score 的结果\n",
    "        \"size\": size  # 只返回一个匹配结果\n",
    "    }\n",
    "    response = es.search(index=index_name, body=search_body)\n",
    "    return response[\"hits\"][\"hits\"]\n",
    "\n",
    "# 从Elasticsearch中提取所有数据\n",
    "def fetch_all_documents(index_name, es):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match_all\": {}\n",
    "        }\n",
    "    }\n",
    "    result = es.search(index=index_name, body=query, scroll='2m')  # 设置scroll保留时间为2分钟\n",
    "    hits = result['hits']['hits']\n",
    "\n",
    "    scroll_id = result['_scroll_id']\n",
    "    total_hits = result['hits']['total']['value']\n",
    "\n",
    "    # 使用scroll API提取所有文档\n",
    "    while len(hits) < total_hits:\n",
    "        result = es.scroll(scroll_id=scroll_id, scroll='2m')\n",
    "        hits += result['hits']['hits']\n",
    "        scroll_id = result['_scroll_id']\n",
    "    \n",
    "    # 提取_source数据\n",
    "    documents = [hit[\"_source\"] for hit in hits]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建索引\n",
    "social_memory_index = \"social_memory\"\n",
    "knowledge_memory_index = \"knowledge_memory\"\n",
    "interaction_memory_index = \"interaction_memory\"\n",
    "create_social_memory_index(social_memory_index)\n",
    "create_knowledge_memory_index(knowledge_memory_index)\n",
    "create_interaction_memory_index(interaction_memory_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从episodic memory里提取记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "from memoryPrompt import Social_Memory_Template, Combine_Social_Template, Valid_JSON_Template\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai(messages, client):\n",
    "    \n",
    "    # Send the prompt to OpenAI's GPT-4\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        stop=None,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_templates(Prompt_Template, input_text):\n",
    "    \"\"\"\n",
    "    Generates template with substituted texts.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Deep copy the original template to avoid modifying it\n",
    "    updated_template = copy.deepcopy(Prompt_Template)\n",
    "        \n",
    "    # Substitute the placeholder in the user document\n",
    "    for entry in updated_template:\n",
    "        if entry[\"role\"] == \"user\":\n",
    "            entry[\"content\"] = entry[\"content\"].format(input_text=input_text)\n",
    "    \n",
    "    return updated_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_templates_combine(Prompt_Template, old_card, new_card):\n",
    "    \"\"\"\n",
    "    Generates template with substituted texts.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Deep copy the original template to avoid modifying it\n",
    "    updated_template = copy.deepcopy(Prompt_Template)\n",
    "        \n",
    "    # Substitute the placeholder in the user document\n",
    "    for entry in updated_template:\n",
    "        if entry[\"role\"] == \"user\":\n",
    "            entry[\"content\"] = entry[\"content\"].format(old_card=old_card, new_card=new_card)\n",
    "    \n",
    "    return updated_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Process each line (each chapter) in the JSONL file\n",
    "filepath = '/Users/elricwan/Downloads/NetmindAI/HarryPotter-memory/episodic_memory/episodic_events.jsonl'\n",
    "with open(filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        event_data = json.loads(line.strip())  # Load the chapter (JSON object)\n",
    "        event_id = list(event_data.keys())[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Social Memory using your templates and OpenAI\n",
    "Social_Memory = generate_templates(Social_Memory_Template, event_data)\n",
    "memory_dict = run_openai(Social_Memory, client)\n",
    "\n",
    "# Strip the markdown delimiters (the ```json part)\n",
    "cleaned_memory_dict = memory_dict.strip('```json').strip()\n",
    "# convert string to dictionary\n",
    "cleaned_memory_dict = json.loads(cleaned_memory_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查找数据库，如果是已有人物或者知识，则更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_social_memory = cleaned_memory_dict['social_memory']\n",
    "current_knowledge_memory = cleaned_memory_dict['knowledge_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ixi2mpIBzk8JZdLAt6ev\n",
      "jBi2mpIBzk8JZdLAt6fo\n",
      "jRi2mpIBzk8JZdLAt6fz\n",
      "jhi2mpIBzk8JZdLAt6f7\n",
      "jxi2mpIBzk8JZdLAuKcF\n",
      "kBi2mpIBzk8JZdLAuKcN\n"
     ]
    }
   ],
   "source": [
    "for person in current_social_memory:\n",
    "    social_query = person['name']\n",
    "    social_fields = ['name', 'other-names']\n",
    "    social_results = search_existing_memory(social_memory_index, social_query, social_fields)\n",
    "    # update interaction memory \n",
    "    interaction_profile = {\n",
    "                \"name\": social_query,\n",
    "                \"event_id\": event_id,\n",
    "                \"description\": person[\"description\"],\n",
    "                \"impression\": person[\"impression\"],\n",
    "                \"interaction\": person[\"interaction\"],\n",
    "            }\n",
    "            \n",
    "    # 保存interaction memory\n",
    "    es.index(index=interaction_memory_index, body=interaction_profile)\n",
    "\n",
    "    # 保存social memory\n",
    "    if not social_results:\n",
    "        es.index(index=social_memory_index, body=person)\n",
    "    else:\n",
    "        # 获取现有数据的ID和_source内容\n",
    "        existing_doc_id = social_results[0]['_id']\n",
    "        existing_profile = social_results[0]['_source']\n",
    "        old_card = existing_profile\n",
    "        new_card = person\n",
    "        # 合并新老profile\n",
    "        #updated_profile = merge_profiles(existing_profile, memory_dict)\n",
    "        Combine_Memory = generate_templates_combine(Combine_Social_Template, old_card, new_card)\n",
    "        combine_memory_dict = run_openai(Combine_Memory, client)\n",
    "\n",
    "        # Strip the markdown delimiters (the ```json part)\n",
    "        cleaned_combine_memory_dict = combine_memory_dict.strip('```json').strip()\n",
    "        # convert string to dictionary\n",
    "        updated_profile = json.loads(cleaned_combine_memory_dict)\n",
    "\n",
    "        # 删除旧文档\n",
    "        es.delete(index=social_memory_index, id=existing_doc_id)\n",
    "\n",
    "        # 保存更新后的文档\n",
    "        es.index(index=social_memory_index, body=updated_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = fetch_all_documents(social_memory_index,es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for knowledge in current_knowledge_memory:\n",
    "    knowledge_query = knowledge['name']\n",
    "    knowledge_fields = ['name', 'description',\"knowledge_content\"]\n",
    "    knowledge_results = search_existing_memory(knowledge_memory_index, knowledge_query, knowledge_fields)\n",
    "    if not knowledge_results:\n",
    "        es.index(index=knowledge_memory_index, body=knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'knowledge_memory',\n",
       "  '_id': 'kRi5mpIBzk8JZdLAjKe4',\n",
       "  '_score': 1.7260926,\n",
       "  '_source': {'name': \"Sorting Hat's Consideration of Personal Choice\",\n",
       "   'description': \"The Sorting Hat at Hogwarts can take into account a student's personal preference when sorting them into a house.\",\n",
       "   'learning_context': 'Harry reassured his son Albus about the Sorting Hat as they prepared for him to board the Hogwarts Express.',\n",
       "   'knowledge_content': \"The Sorting Hat will consider a student's personal choice in addition to its own judgment when sorting them into a house.\",\n",
       "   'outcome': 'Harry reassured Albus, helping alleviate his concerns about being sorted into a house he might not prefer.'}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = fetch_all_documents(knowledge_memory_index,es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': \"Sorting Hat's Consideration of Personal Choice\",\n",
       "  'description': \"The Sorting Hat at Hogwarts can take into account a student's personal preference when sorting them into a house.\",\n",
       "  'learning_context': 'Harry reassured his son Albus about the Sorting Hat as they prepared for him to board the Hogwarts Express.',\n",
       "  'knowledge_content': \"The Sorting Hat will consider a student's personal choice in addition to its own judgment when sorting them into a house.\",\n",
       "  'outcome': 'Harry reassured Albus, helping alleviate his concerns about being sorted into a house he might not prefer.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 综合之前的功能，完整的提取记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_social_memory(input_text, client):\n",
    "    \"\"\"\n",
    "    Extracts social memory from the given input text.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Generate Social Memory using your templates and OpenAI\n",
    "    Social_Memory = generate_templates(Social_Memory_Template, input_text)\n",
    "    memory_dict = run_openai(Social_Memory, client)\n",
    "\n",
    "    # Strip the markdown delimiters (the ```json part)\n",
    "    cleaned_memory_dict = memory_dict.strip('```json').strip()\n",
    "    try:\n",
    "        cleaned_memory_dict = json.loads(cleaned_memory_dict)\n",
    "    except:\n",
    "        Json_Template = generate_templates(Valid_JSON_Template, memory_dict)\n",
    "        memory_dict = run_openai(Json_Template, client)\n",
    "        cleaned_memory_dict = memory_dict.strip('```json').strip()\n",
    "        cleaned_memory_dict = json.loads(cleaned_memory_dict)\n",
    "    \n",
    "    return cleaned_memory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_social_profile(old_card,new_card):\n",
    "    Combine_Memory = generate_templates_combine(Combine_Social_Template, old_card, new_card)\n",
    "    combine_memory_dict = run_openai(Combine_Memory, client)\n",
    "    # Strip the markdown delimiters (the ```json part)\n",
    "    cleaned_combine_memory_dict = combine_memory_dict.strip('```json').strip()\n",
    "    try:\n",
    "        # convert string to dictionary\n",
    "        updated_profile = json.loads(cleaned_combine_memory_dict)\n",
    "    except:\n",
    "        Json_Template = generate_templates(Valid_JSON_Template, combine_memory_dict)\n",
    "        combine_memory_dict = run_openai(Json_Template, client)\n",
    "        cleaned_combine_memory_dict = combine_memory_dict.strip('```json').strip()\n",
    "        updated_profile = json.loads(cleaned_combine_memory_dict)\n",
    "    \n",
    "    return updated_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "count = 0\n",
    "\n",
    "# Process each line (each chapter) in the JSONL file\n",
    "filepath = '/Users/elricwan/Downloads/NetmindAI/HarryPotter-memory/episodic_memory/episodic_events.jsonl'\n",
    "with open(filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        count += 1\n",
    "        if count > 100:\n",
    "            continue\n",
    "        event_data = json.loads(line.strip())  # Load the chapter (JSON object)\n",
    "        event_id = list(event_data.keys())[0]  \n",
    "        # collect social memory for this event\n",
    "        cleaned_memory_dict = extract_social_memory(event_data, client)\n",
    "\n",
    "        current_social_memory = cleaned_memory_dict['social_memory']\n",
    "        current_knowledge_memory = cleaned_memory_dict['knowledge_memory']\n",
    "\n",
    "        for person in current_social_memory:\n",
    "            social_query = person['name']\n",
    "            social_fields = ['name', 'other-names']\n",
    "            social_results = search_existing_memory(social_memory_index, social_query, social_fields)\n",
    "            # update interaction memory \n",
    "            interaction_profile = {\n",
    "                        \"name\": social_query,\n",
    "                        \"event_id\": event_id,\n",
    "                        \"description\": person[\"description\"],\n",
    "                        \"impression\": person[\"impression\"],\n",
    "                        \"interaction\": person[\"interaction\"],\n",
    "                    }\n",
    "                    \n",
    "            # 保存interaction memory\n",
    "            es.index(index=interaction_memory_index, body=interaction_profile)\n",
    "\n",
    "            # 保存social memory\n",
    "            if not social_results:\n",
    "                es.index(index=social_memory_index, body=person)\n",
    "            else:\n",
    "                # 获取现有数据的ID和_source内容\n",
    "                existing_doc_id = social_results[0]['_id']\n",
    "                existing_profile = social_results[0]['_source']\n",
    "                old_card = existing_profile\n",
    "                new_card = person\n",
    "                \n",
    "                updated_profile = update_social_profile(old_card,new_card)\n",
    "                try:\n",
    "                    # 删除旧文档\n",
    "                    es.delete(index=social_memory_index, id=existing_doc_id)\n",
    "                except:\n",
    "                    time.sleep(1)\n",
    "\n",
    "                # 保存更新后的文档\n",
    "                for update_pro in updated_profile['merged_profile']:\n",
    "                    es.index(index=social_memory_index, body=update_pro)\n",
    "                \n",
    "        for knowledge in current_knowledge_memory:\n",
    "            knowledge_query = knowledge['name']\n",
    "            knowledge_fields = ['name', 'description',\"knowledge_content\"]\n",
    "            knowledge_results = search_existing_memory(knowledge_memory_index, knowledge_query, knowledge_fields)\n",
    "            if not knowledge_results:\n",
    "                es.index(index=knowledge_memory_index, body=knowledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data to jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = fetch_all_documents(social_memory_index,es)\n",
    "doc2 = fetch_all_documents(knowledge_memory_index,es)\n",
    "doc3 = fetch_all_documents(interaction_memory_index,es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_jsonl(documents, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for document in documents:\n",
    "            f.write(json.dumps(document) + '\\n')\n",
    "\n",
    "# Sort doc3 by event_id before saving\n",
    "if 'event_id' in doc3[0]:\n",
    "    doc3 = sorted(doc3, key=lambda x: int(re.findall(r'\\d+', x['event_id'])[0]))\n",
    "\n",
    "# Save the data to JSONL files\n",
    "save_to_jsonl(doc1, 'social_memory.jsonl')\n",
    "save_to_jsonl(doc2, 'knowledge_memory.jsonl')\n",
    "save_to_jsonl(doc3, 'interaction_memory.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
